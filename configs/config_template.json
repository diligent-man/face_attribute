{
    "EXPERIMENTS":
    {
        "PROJECT_NAME": "face_attribute"
    },

    "DATA":
    {
        // Absolute path to the dataset
        "DATASET_NAME": "",

        // List of H, W, C of an image
        "INPUT_SHAPE": [],

        // Ratio for train/ val splitting
        "TRAIN_SIZE": 0.9,

        // Num of images each batch
        "BATCH_SIZE": 360,

        // Num of processes used for image transformation when loading by dataloader
        // Should not be over 2 * cpu_count() + 1
        // Work better with Linux if NUM_WORKERS is large
        "NUM_WORKERS": 4,

        // Transformations for input
        //NAME_LIST: Transformation name
        //ARGS: Corresponding args of each transformation
        // Ref: https://pytorch.org/vision/stable/transforms.html
        // Note: Support only v2 transformation APIs
        "TRANSFORM": {
            "NAME_LIST": [
                //Transformation_name_must_be_similar_with_name_from_pytorch_doc
                // Example
                "Resize",
                "PILToTensor",
                "ToDtype"
            ],
            "ARGS": {
                "0": {
                    "size": [224, 224],
                    "interpolation": "BICUBIC",
                    "antialias": true
                },
                "1": {},
                "2": {
                    "dtype": "float32",
                    "scale": true
                }
            }
        },

        // Transformations for labels
        // Structure is the same as input transformation
        "TARGET_TRANSFORM": {}
    },

    "CHECKPOINT":
    {
        // Absolute path to the directory for saving and loading checkpoint
        "PATH": "Absolute_path",

        // "no" | "epoch" | "steps"
        "SAVE_STRATEGY": "no",

        // Number of updates steps before two checkpoint saves if `save_strategy="steps"
        "SAVE_STEPS": 500,

        // Limit the total amount of checkpoints. Based on metric_for_best_model
        // -1 for saving all
        "SAVE_TOTAL_LIMIT": 5,

        // Load old checkpoint or not
        "LOAD": false,

        // Resume name when loading old checkpoint
        // Only work with .pt checkpoint
        "RESUME_NAME": "checkpoint_name.pt"
    },

    // Num of training epochs
    "NUM_EPOCH": 1,

    // Metrics when trainning/ testing
    // Ref: https://pytorch.org/torcheval/stable/torcheval.metrics.html
    "METRICS":
    {
        // Used with EARLY_STOPPING
        "METRICS_FOR_BEST_MODEL": "",
        // Structure is the same as transformation for input and label
        "NAME_LIST": [],
        "ARGS":{}

    },

    "MODEL":
    {
        // Base backbone
        // E.g. resnet
        "BASE": "",

        // Backbone's variant
        // E.g. Resnet18
        "NAME": "",

        // Use pretrained weight or not
        // TODO: Handle pretrained weight when init model
        "PRETRAINED": false,

        // ARGS to model
        "ARGS": {}
    },

    // Ref: https://pytorch.org/docs/stable/optim.html
    "OPTIMIZER":
        {
            "NAME": "Adam",
            "ARGS": {}
        },

    // Ref: https://pytorch.org/docs/stable/optim.html#module-torch.optim.lr_scheduler
    "LR_SCHEDULER":
        {
            "NAME": "",
            "ARGS": {}
        },

    // Ref: https://pytorch.org/docs/stable/nn.html
    "LOSS":
    {
        "NAME": "",
        "ARGS": {}
    },

    "EARLY_STOPPING":
    {
        // Apply early stopping when training or not
        "APPLY": false,
        // Use with 'metric_for_best_model'
        // Num of epoch to cease training when the specified METRICS_FOR_BEST_MODEL worsens in evaluation phase
        "PATIENCE": 5,
        // How much the METRICS_FOR_BEST_MODEL must improve to satisfy early stopping conditions.
        "MIN_DELTA": 0
    },

    // Misc configs
    "SEED": 12345,
    "CUDA": true
}